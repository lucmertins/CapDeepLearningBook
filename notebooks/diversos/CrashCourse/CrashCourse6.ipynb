{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando [Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/6-train-nn.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import np, npx, gluon, init, autograd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../scripts/CrashCourse'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from prepare_dataset import process_dataset\n",
    "\n",
    "mx.np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isdir('../../../data/crashCourse/c6/plants') and not os.path.isdir('../../../data/crashCourse/c6/datasets'):\n",
    "\n",
    "    url='https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/hb74ynkjcn-1.zip'\n",
    "\n",
    "    os.makedirs('../../../data/crashCourse/c6/',exist_ok=True)\n",
    "\n",
    "    zip_file_path=mx.gluon.utils.download(url,path='../../../data/crashCourse/c6/')\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path,'r') as zf:\n",
    "        zf.extractall(path='../../../data/crashCourse/c6/plants')\n",
    "\n",
    "    os.remove(zip_file_path)    \n",
    "\n",
    "else:\n",
    "    print('Nada a fazer, pois arquivos já estão lá')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('../../../data/crashCourse/c6/datasets'):\n",
    "    process_dataset('../../../data/crashCourse/c6/plants',path='../../../data/crashCourse/c6')\n",
    "else:\n",
    "    print('Nada a fazer, pois arquivos já estão lá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=gluon.data.vision.ImageFolderDataset('../../../data/crashCourse/c6/datasets/train')\n",
    "val_dataset=gluon.data.vision.ImageFolderDataset('../../../data/crashCourse/c6/datasets/validation')\n",
    "test_dataset=gluon.data.vision.ImageFolderDataset('../../../data/crashCourse/c6/datasets/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx=888\n",
    "sample=train_dataset[sample_idx]\n",
    "data=sample[0]\n",
    "label=sample[1]\n",
    "\n",
    "plt.imshow(data.asnumpy())\n",
    "print(f\"Data type: {data.dtype}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Label description: {train_dataset.synsets[label]}\")\n",
    "print(f\"Image shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "Using transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "jitter_param=0.05\n",
    "\n",
    "mean=[0.485,0.456,0.406]\n",
    "std=[0.229,0.224,0.255]\n",
    "\n",
    "training_transformer=transforms.Compose([\n",
    "    transforms.Resize(size=224,keep_ratio=True),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomColorJitter(contrast=jitter_param),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "validation_transformer=transforms.Compose([\n",
    "    transforms.Resize(size=224,keep_ratio=True),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "\n",
    "train_loader=gluon.data.DataLoader(train_dataset.transform_first(training_transformer),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "validation_loader=gluon.data.DataLoader(val_dataset.transform_first(validation_transformer),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "\n",
    "test_loader=gluon.data.DataLoader(val_dataset.transform_first(validation_transformer),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True)                     \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch,columns=4,fig_size=(9,5),pad=1):\n",
    "    labels=batch[1].asnumpy()\n",
    "    batch=batch[0]/2+0.5\n",
    "    batch=np.clip(batch.asnumpy(),0,1)\n",
    "    size=batch.shape[0]\n",
    "    rows=int(size/columns)\n",
    "    fig, axes=plt.subplots(rows,columns,figsize=fig_size)\n",
    "    for ax,img,label in zip(axes.flatten(),batch,labels):\n",
    "        ax.imshow(np.transpose(img,(1,2,0)))\n",
    "        ax.set(title=f\"Label: {label}\")\n",
    "    fig.tight_layout(h_pad=pad,w_pad=pad)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    a=batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create neural network\n",
    "\n",
    "The convolutional block has a convolution layer, a max pool layer and a batch normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters,kernel_size=2,stride=2,batch_norm=True):\n",
    "    conv_block=nn.HybridSequential()\n",
    "    conv_block.add(nn.Conv2D(channels=filters,kernel_size=kernel_size,activation='relu'),\n",
    "                                nn.MaxPool2D(pool_size=4,strides=stride))\n",
    "    if batch_norm:\n",
    "        conv_block.add(nn.BatchNorm())\n",
    "    return conv_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dense block consists of a dense layer and a dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(neurons,activation='relu',dropout=0.2):\n",
    "    dense_block=nn.HybridSequential()\n",
    "    dense_block.add(nn.Dense(neurons,activation=activation))\n",
    "    if dropout:\n",
    "        dense_block.add(nn.Dropout(dropout))\n",
    "    return dense_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create neural network blueprint using blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNetwork(nn.HybridBlock):\n",
    "    def __init__(self):\n",
    "        super(LeafNetwork, self).__init__()\n",
    "        self.conv1 = conv_block(32)\n",
    "        self.conv2 = conv_block(64)\n",
    "        self.conv3 = conv_block(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = dense_block(100)\n",
    "        self.dense2 = dense_block(10)\n",
    "        self.dense3 = nn.Dense(2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch = self.conv1(batch)\n",
    "        batch = self.conv2(batch)\n",
    "        batch = self.conv3(batch)\n",
    "        batch = self.flatten(batch)\n",
    "        batch = self.dense1(batch)\n",
    "        batch = self.dense2(batch)\n",
    "        batch = self.dense3(batch)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model based on the blueprint provided and initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=mx.gpu()\n",
    "\n",
    "initializer=mx.initializer.Xavier()\n",
    "\n",
    "model=LeafNetwork()\n",
    "\n",
    "model.initialize(initializer,device=device)\n",
    "model.summary(mx.np.random.uniform(size=(4,3,128,128),device=device))\n",
    "model.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Optimizer and Loss funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer='sgd'\n",
    "\n",
    "optimizer_params={'learning_rate':0.001}\n",
    "\n",
    "trainer=gluon.Trainer(model.collect_params(), optimizer,optimizer_params)\n",
    "\n",
    "loss_fn=gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the accuracy for the validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_data):\n",
    "    acc=gluon.metric.Accuracy()\n",
    "    for batch in val_data:\n",
    "        data=batch[0]\n",
    "        labels=batch[1]\n",
    "        outputs=model(data.to_device(device))\n",
    "        acc.update([labels],[outputs])\n",
    "\n",
    "    _,accuracy=acc.get()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2\n",
    "accuracy=gluon.metric.Accuracy()\n",
    "log_interval=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic=time.time()\n",
    "    btic=time.time()\n",
    "    accuracy.reset()\n",
    "\n",
    "    for idx,batch in enumerate(train_loader):\n",
    "        data=batch[0]\n",
    "        label=batch[1]\n",
    "        with mx.autograd.record():\n",
    "            outputs=model(data.to_device(device))\n",
    "            loss=loss_fn(outputs,label.to_device(device))\n",
    "        mx.autograd.backward(loss)\n",
    "        trainer.step(batch_size)\n",
    "        accuracy.update([label],[outputs])\n",
    "        if log_interval and (idx+1)%log_interval==0:\n",
    "            _,acc=accuracy.get()\n",
    "            print(f\"\"\"Epoch[{epoch + 1}] Batch[{idx + 1}] Speed: {batch_size / (time.time() - btic)} samples/sec \\\n",
    "                  batch loss = {loss.mean().item()} | accuracy = {acc}\"\"\")\n",
    "            btic = time.time()\n",
    "\n",
    "    _, acc = accuracy.get()\n",
    "\n",
    "    acc_val = test(validation_loader)\n",
    "    print(f\"[Epoch {epoch + 1}] training: accuracy={acc}\")\n",
    "    print(f\"[Epoch {epoch + 1}] time cost: {time.time() - tic}\")\n",
    "    print(f\"[Epoch {epoch + 1}] validation: validation accuracy={acc_val}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
