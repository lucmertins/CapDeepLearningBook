{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando [Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/2-create-nn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create neural network\n",
    "Uma camada com 3 entradas e 5 saidas, com função de ativação \"RELU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(3 -> 5, Activation(relu))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dez linhas com três parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9304558 ,  0.62095165,  0.57590795],\n",
       "       [-0.23812461,  0.4895475 ,  0.40970135],\n",
       "       [ 0.8304789 ,  0.83184505, -0.2338106 ],\n",
       "       [ 0.25073445, -0.80570596,  0.57387054],\n",
       "       [ 0.06210291,  0.50480986,  0.7998245 ],\n",
       "       [-0.30788028,  0.8492992 ,  0.11609352],\n",
       "       [-0.5782545 ,  0.74868107, -0.32136083],\n",
       "       [-0.17012817, -0.34187388,  0.7680478 ],\n",
       "       [-0.359024  ,  0.6662005 , -0.94704115],\n",
       "       [ 0.31440222, -0.69534445, -0.03637332]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.random.uniform(-1,1,(10,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.00695837, 0.02151532],\n",
       "       [0.        , 0.0196271 , 0.        , 0.06759939, 0.        ],\n",
       "       [0.03224901, 0.00728238, 0.        , 0.        , 0.03928804],\n",
       "       [0.        , 0.        , 0.06608538, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.06925236, 0.        ],\n",
       "       [0.01515879, 0.05853312, 0.        , 0.07884857, 0.        ],\n",
       "       [0.03958181, 0.09199545, 0.        , 0.06745759, 0.        ],\n",
       "       [0.        , 0.        , 0.04870468, 0.03085256, 0.        ],\n",
       "       [0.07424875, 0.10676001, 0.        , 0.01475125, 0.01642966],\n",
       "       [0.        , 0.        , 0.03956246, 0.        , 0.00527947]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter (shape=(5, 3), dtype=float32),\n",
       " 'bias': Parameter (shape=(5,), dtype=float32)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pesos e bias de entrada de cada elemento da camada interna de 5 neuronios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00296517,  0.02493882, -0.05973333],\n",
       "       [-0.06011468,  0.05420877, -0.05180714],\n",
       "       [-0.01905191, -0.06704587,  0.02934997],\n",
       "       [-0.06633657,  0.06156359,  0.05287929],\n",
       "       [ 0.03232814,  0.00826898, -0.02378718]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain layers into a neural network using nn.Sequential\n",
    "\n",
    "Sequential é a ligação de camadas onde a saída de uma camada é a entrada de outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(3 -> 5, Activation(relu))\n",
       "  (1): Dense(-1 -> 25, Activation(relu))\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "\n",
    "net.add(nn.Dense(5,in_units=3,activation='relu'),nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(-1 -> 25, Activation(relu))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom neural network architecture flexibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(5,activation='relu')\n",
    "        self.dense2=nn.Dense(25,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (dense1): Dense(-1 -> 5, Activation(relu))\n",
       "  (dense2): Dense(-1 -> 25, Activation(relu))\n",
       "  (dense3): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=MLP()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter (shape=(5, -1), dtype=float32),\n",
       " 'bias': Parameter (shape=(5,), dtype=float32)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dense1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating custom layers using Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter (shape=(5, -1), dtype=<class 'numpy.float32'>),\n",
       " Parameter (shape=(5, -1), dtype=<class 'numpy.float32'>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon import Parameter\n",
    "\n",
    "weight=Parameter(\"custom_parameter_weight\",shape=(5,-1))\n",
    "bias=Parameter(\"custom_parameter_bias\",shape=(5,-1))\n",
    "\n",
    "weight,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layer com função linear sem função de ativação. \n",
    "\n",
    "w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_layer(nn.Block):\n",
    "    def __init__(self,out_units, in_units=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mxnet 2.0\n",
    "        self.weight=Parameter(\"weight\",shape=(in_units,out_units),allow_deferred_init=True)\n",
    "        self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "        # mxnet 1.8.0\n",
    "        # self.weight = self.params.get('weight', shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        # self.bias = self.params.get('bias', shape=(out_units,),allow_deferred_init=True)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01971773, -0.05515386, -0.07169655],\n",
       "       [-0.01348839, -0.05879273, -0.04236437],\n",
       "       [-0.06800018, -0.07280456, -0.01472434],\n",
       "       [ 0.00791047, -0.05942319, -0.04943746]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense=custom_layer(3,in_units=5)\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LeNet](http://yann.lecun.com/exdb/lenet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=nn.Dense(10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet=LeNet()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_custom(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=custom_layer(10,84)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet_custom=LeNet_custom()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet:\n",
      "[[-6.8408676e-04  2.3123024e-03  3.8441597e-04  7.9229695e-04\n",
      "   8.2185236e-04 -2.0441706e-03 -1.9353793e-03  1.3393344e-03\n",
      "  -5.3992699e-04 -9.2347735e-05]]\n",
      "Custom LeNet:\n",
      "[[ 4.5696136e-02 -4.4086133e-05  2.1577444e-02  3.3180423e-02\n",
      "   5.8146108e-02  6.3894823e-02  4.6673581e-02  8.2850773e-03\n",
      "  -1.7607763e-02  2.0094015e-02]]\n"
     ]
    }
   ],
   "source": [
    "image_data=np.random.uniform(-1,1,(1,1,28,28))\n",
    "\n",
    "lenet.initialize()\n",
    "lenet_custom.initialize()\n",
    "\n",
    "print(\"LeNet:\")\n",
    "print(lenet(image_data))\n",
    "\n",
    "print(\"Custom LeNet:\")\n",
    "print(lenet_custom(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1, 3, 3), (120,), (6, 1, 3, 3), (120,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.conv1.weight.data().shape, lenet.dense1.bias.data().shape,lenet_custom.conv1.weight.data().shape, lenet_custom.dense1.bias.data().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predefined (pretrained) architectures\n",
    "\n",
    "[Gluon CV model zoo](https://cv.gluon.ai/model_zoo/index.html)\n",
    "\n",
    "[Gluon NLP model zoo](https://nlp.gluon.ai/model_zoo/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon import model_zoo\n",
    "\n",
    "net=model_zoo.vision.resnet50_v2(pretrained=True)\n",
    "net.hybridize()\n",
    "\n",
    "dummy_input=np.ones(shape=(1,3,224,224))\n",
    "output=net(dummy_input)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding the paradigm for your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridSequential(\n",
       "  (0): Dense(3 -> 5, Activation(relu))\n",
       "  (1): Dense(-1 -> 25, Activation(relu))\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add(nn.Dense(5,in_units=3,activation='relu'),\n",
    "    nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid_seq.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom layers using Parameters(HbridBlocks API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 3) (4, 5)\n",
      "(5, 3) (3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.11437228,  0.10194876, -0.04716104],\n",
       "       [-0.11570357,  0.07732303, -0.08061042],\n",
       "       [-0.15427211, -0.04824062, -0.07051762],\n",
       "       [-0.16056198,  0.08461182, -0.08503564]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLayer(nn.HybridBlock):\n",
    "    def __init__(self,out_units, in_units=-1):\n",
    "        super().__init__()\n",
    "        self.weight=Parameter(\"weight\",shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(self.weight.shape,self.bias.shape)\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()\n",
    "\n",
    "    def infer_shape(self,x):\n",
    "        print(self.weight.shape,x.shape)\n",
    "        self.weight.shape=(x. shape[-1],self.weight.shape[1])\n",
    "\n",
    "\n",
    "dense=CustomLayer(3)\n",
    "\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hybridizing: 0.5018 sec\n",
      "After hybridizing: 0.1699\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "def benchmark(net,x):\n",
    "    y=net(x)\n",
    "    start=time()\n",
    "    for i in range(1,1000):\n",
    "        y=net(x)\n",
    "    return time()-start\n",
    "\n",
    "\n",
    "x_bench=np.random.normal(size=(1,521))\n",
    "\n",
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add (nn.Dense(256,activation='relu'),\n",
    "                nn.Dense(128,activation='relu'),\n",
    "                nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid_seq, x_bench)))\n",
    "net_hybrid_seq.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid_seq, x_bench)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hybridizing: 0.5161 sec\n",
      "After hybridizing: 0.2285\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import HybridBlock\n",
    "\n",
    "class MLP_Hybrid(HybridBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(256,activation='relu')\n",
    "        self.dense2=nn.Dense(123,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3\n",
    "\n",
    "net_hybrid=MLP_Hybrid()\n",
    "net_hybrid.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid, x_bench)))\n",
    "net_hybrid.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid, x_bench)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Loading your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='../../../data/crashCourse/models/layer.params'\n",
    "layer.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "    return layer\n",
    "\n",
    "layer_new=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_new.load_parameters(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/load the model weights/parameters and the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../data/crashCourse/models/MLP_hybrid-symbol.json',\n",
       " '../../../data/crashCourse/models/MLP_hybrid-0000.params')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_hybrid.export('../../../data/crashCourse/models/MLP_hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    net_loaded=nn.SymbolBlock.imports('../../../data/crashCourse/models/MLP_hybrid-symbol.json',['data'], '../../../data/crashCourse/models/MLP_hybrid-0000.params',device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08079498,  0.10126774]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_loaded(x_bench)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                                     (10, 3)               0\n",
      "        Activation-1                                     (10, 5)               0\n",
      "             Dense-2                                     (10, 5)              20\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 20\n",
      "   Trainable params: 20\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 20\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "layer.summary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                              (1, 1, 28, 28)               0\n",
      "        Activation-1                              (1, 6, 26, 26)               0\n",
      "            Conv2D-2                              (1, 6, 26, 26)              60\n",
      "         MaxPool2D-3                              (1, 6, 13, 13)               0\n",
      "        Activation-4                             (1, 16, 11, 11)               0\n",
      "            Conv2D-5                             (1, 16, 11, 11)             880\n",
      "         MaxPool2D-6                               (1, 16, 5, 5)               0\n",
      "        Activation-7                                    (1, 120)               0\n",
      "             Dense-8                                    (1, 120)           48120\n",
      "        Activation-9                                     (1, 84)               0\n",
      "            Dense-10                                     (1, 84)           10164\n",
      "            Dense-11                                     (1, 10)             850\n",
      "            LeNet-12                                     (1, 10)               0\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 60074\n",
      "   Trainable params: 60074\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 60074\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lenet.summary(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                                    (1, 521)               0\n",
      "        Activation-1                                    (1, 256)               0\n",
      "             Dense-2                                    (1, 256)          133632\n",
      "        Activation-3                                    (1, 123)               0\n",
      "             Dense-4                                    (1, 123)           31611\n",
      "             Dense-5                                      (1, 2)             248\n",
      "        MLP_Hybrid-6                                      (1, 2)               0\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 165491\n",
      "   Trainable params: 165491\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 165491\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net_hybrid_summary=MLP_Hybrid()\n",
    "\n",
    "net_hybrid_summary.initialize()\n",
    "\n",
    "net_hybrid_summary.summary(x_bench)\n",
    "\n",
    "net_hybrid_summary.hybridize()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
