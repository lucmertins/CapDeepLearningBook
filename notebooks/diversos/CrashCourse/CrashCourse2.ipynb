{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando [Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/2-create-nn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create neural network\n",
    "Uma camada com 3 entradas e 5 saidas, com função de ativação \"RELU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(3 -> 5, Activation(relu))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:17:14] /home/mertins/Desenvolvimento/C/Terceiros/mxnet/src/storage/storage.cc:202: Using Pooled (Naive) StorageManager for CPU\n"
     ]
    }
   ],
   "source": [
    "layer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dez linhas com três parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88657403,  0.9273255 , -0.45468742],\n",
       "       [-0.23311698, -0.04466975,  0.5834501 ],\n",
       "       [ 0.62433743,  0.0577898 , -0.04004568],\n",
       "       [ 0.13608909, -0.21443039,  0.8511933 ],\n",
       "       [ 0.6721575 , -0.8579279 , -0.32520765],\n",
       "       [-0.8257414 ,  0.2963438 , -0.9595632 ],\n",
       "       [-0.2635169 ,  0.6652397 ,  0.91431034],\n",
       "       [ 0.5563135 , -0.7192985 ,  0.7400243 ],\n",
       "       [ 0.74017453,  0.95723665, -0.05278391],\n",
       "       [ 0.59831715,  0.60182154, -0.07704127]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.random.uniform(-1,1,(10,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.04437108, 0.01096384, 0.        ],\n",
       "       [0.01540359, 0.01735983, 0.        , 0.        , 0.03530429],\n",
       "       [0.00381139, 0.02891595, 0.0071606 , 0.01262893, 0.        ],\n",
       "       [0.02378628, 0.04612946, 0.        , 0.        , 0.05157538],\n",
       "       [0.        , 0.00375629, 0.        , 0.        , 0.00060787],\n",
       "       [0.        , 0.        , 0.01947428, 0.00730047, 0.        ],\n",
       "       [0.03439108, 0.04268821, 0.02091249, 0.        , 0.03359453],\n",
       "       [0.01674652, 0.05354869, 0.        , 0.        , 0.05611669],\n",
       "       [0.01591048, 0.04680086, 0.05175146, 0.03321034, 0.        ],\n",
       "       [0.00959048, 0.03363482, 0.03384075, 0.02388959, 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter (shape=(5, 3), dtype=float32),\n",
       " 'bias': Parameter (shape=(5,), dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pesos e bias de entrada de cada elemento da camada interna de 5 neuronios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0068339 ,  0.01299825,  0.0301265 ],\n",
       "       [ 0.04819721,  0.01438687,  0.05011239],\n",
       "       [ 0.00628365,  0.04861524, -0.01068833],\n",
       "       [ 0.01729892,  0.02042518, -0.01618656],\n",
       "       [-0.00873779, -0.02834515,  0.05484822]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain layers into a neural network using nn.Sequential\n",
    "\n",
    "Sequential é a ligação de camadas onde a saída de uma camada é a entrada de outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(3 -> 5, Activation(relu))\n",
       "  (1): Dense(-1 -> 25, Activation(relu))\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "\n",
    "net.add(nn.Dense(5,in_units=3,activation='relu'),nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(-1 -> 25, Activation(relu))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom neural network architecture flexibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(5,activation='relu')\n",
    "        self.dense2=nn.Dense(25,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (dense1): Dense(-1 -> 5, Activation(relu))\n",
       "  (dense2): Dense(-1 -> 25, Activation(relu))\n",
       "  (dense3): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=MLP()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter (shape=(5, -1), dtype=float32),\n",
       " 'bias': Parameter (shape=(5,), dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dense1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating custom layers using Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter (shape=(5, -1), dtype=<class 'numpy.float32'>),\n",
       " Parameter (shape=(5, -1), dtype=<class 'numpy.float32'>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon import Parameter\n",
    "\n",
    "weight=Parameter(\"custom_parameter_weight\",shape=(5,-1))\n",
    "bias=Parameter(\"custom_parameter_bias\",shape=(5,-1))\n",
    "\n",
    "weight,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layer com função linear sem função de ativação. \n",
    "\n",
    "w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_layer(nn.Block):\n",
    "    def __init__(self,out_units, in_units=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mxnet 2.0\n",
    "        self.weight=Parameter(\"weight\",shape=(in_units,out_units),allow_deferred_init=True)\n",
    "        self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "        # mxnet 1.8.0\n",
    "        # self.weight = self.params.get('weight', shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        # self.bias = self.params.get('bias', shape=(out_units,),allow_deferred_init=True)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02481367,  0.007271  ,  0.06815495],\n",
       "       [-0.0675921 , -0.06589589,  0.04664002],\n",
       "       [-0.05190407, -0.01203752,  0.05761838],\n",
       "       [-0.03687233, -0.00421239,  0.06642268]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense=custom_layer(3,in_units=5)\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LeNet](http://yann.lecun.com/exdb/lenet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=nn.Dense(10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet=LeNet()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_custom(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=custom_layer(10,84)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet_custom=LeNet_custom()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet:\n",
      "[[ 0.00089368 -0.00399038  0.00011905  0.00163105 -0.00089482 -0.00210765\n",
      "   0.00552988  0.00021146  0.00221306 -0.00193633]]\n",
      "Custom LeNet:\n",
      "[[ 0.02705444  0.06015968 -0.06345475  0.02835384  0.05397669 -0.0451556\n",
      "   0.04637432 -0.00195986  0.00080239 -0.05106261]]\n"
     ]
    }
   ],
   "source": [
    "image_data=np.random.uniform(-1,1,(1,1,28,28))\n",
    "\n",
    "lenet.initialize()\n",
    "lenet_custom.initialize()\n",
    "\n",
    "print(\"LeNet:\")\n",
    "print(lenet(image_data))\n",
    "\n",
    "print(\"Custom LeNet:\")\n",
    "print(lenet_custom(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1, 3, 3), (120,), (6, 1, 3, 3), (120,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.conv1.weight.data().shape, lenet.dense1.bias.data().shape,lenet_custom.conv1.weight.data().shape, lenet_custom.dense1.bias.data().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predefined (pretrained) architectures\n",
    "\n",
    "[Gluon CV model zoo](https://cv.gluon.ai/model_zoo/index.html)\n",
    "\n",
    "[Gluon NLP model zoo](https://nlp.gluon.ai/model_zoo/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon import model_zoo\n",
    "\n",
    "net=model_zoo.vision.resnet50_v2(pretrained=True)\n",
    "net.hybridize()\n",
    "\n",
    "dummy_input=np.ones(shape=(1,3,224,224))\n",
    "output=net(dummy_input)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding the paradigm for your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridSequential(\n",
       "  (0): Dense(3 -> 5, Activation(relu))\n",
       "  (1): Dense(-1 -> 25, Activation(relu))\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add(nn.Dense(5,in_units=3,activation='relu'),\n",
    "    nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid_seq.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom layers using Parameters(HbridBlocks API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 3) (4, 5)\n",
      "(5, 3) (3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00016055, -0.09525858, -0.02461037],\n",
       "       [ 0.00876564, -0.08444627,  0.02188295],\n",
       "       [ 0.04412797, -0.0623582 ,  0.03239645],\n",
       "       [-0.00077351, -0.04988677, -0.0135352 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLayer(nn.HybridBlock):\n",
    "    def __init__(self,out_units, in_units=-1):\n",
    "        super().__init__()\n",
    "        self.weight=Parameter(\"weight\",shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(self.weight.shape,self.bias.shape)\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()\n",
    "\n",
    "    def infer_shape(self,x):\n",
    "        print(self.weight.shape,x.shape)\n",
    "        self.weight.shape=(x. shape[-1],self.weight.shape[1])\n",
    "\n",
    "\n",
    "dense=CustomLayer(3)\n",
    "\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hybridizing: 0.4124 sec\n",
      "After hybridizing: 0.1314\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "def benchmark(net,x):\n",
    "    y=net(x)\n",
    "    start=time()\n",
    "    for i in range(1,1000):\n",
    "        y=net(x)\n",
    "    return time()-start\n",
    "\n",
    "\n",
    "x_bench=np.random.normal(size=(1,521))\n",
    "\n",
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add (nn.Dense(256,activation='relu'),\n",
    "                nn.Dense(128,activation='relu'),\n",
    "                nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid_seq, x_bench)))\n",
    "net_hybrid_seq.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid_seq, x_bench)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hybridizing: 0.3998 sec\n",
      "After hybridizing: 0.1177\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import HybridBlock\n",
    "\n",
    "class MLP_Hybrid(HybridBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(256,activation='relu')\n",
    "        self.dense2=nn.Dense(123,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3\n",
    "\n",
    "net_hybrid=MLP_Hybrid()\n",
    "net_hybrid.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid, x_bench)))\n",
    "net_hybrid.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid, x_bench)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Loading your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='../../../data/crashCourse/models/layer.params'\n",
    "layer.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "    return layer\n",
    "\n",
    "layer_new=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_new.load_parameters(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/load the model weights/parameters and the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../data/crashCourse/models/MLP_hybrid-symbol.json',\n",
       " '../../../data/crashCourse/models/MLP_hybrid-0000.params')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_hybrid.export('../../../data/crashCourse/models/MLP_hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    net_loaded=nn.SymbolBlock.imports('../../../data/crashCourse/models/MLP_hybrid-symbol.json',['data'], '../../../data/crashCourse/models/MLP_hybrid-0000.params',device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11246412, -0.0175273 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_loaded(x_bench)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                                     (10, 3)               0\n",
      "        Activation-1                                     (10, 5)               0\n",
      "             Dense-2                                     (10, 5)              20\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 20\n",
      "   Trainable params: 20\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 20\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "layer.summary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                              (1, 1, 28, 28)               0\n",
      "        Activation-1                              (1, 6, 26, 26)               0\n",
      "            Conv2D-2                              (1, 6, 26, 26)              60\n",
      "         MaxPool2D-3                              (1, 6, 13, 13)               0\n",
      "        Activation-4                             (1, 16, 11, 11)               0\n",
      "            Conv2D-5                             (1, 16, 11, 11)             880\n",
      "         MaxPool2D-6                               (1, 16, 5, 5)               0\n",
      "        Activation-7                                    (1, 120)               0\n",
      "             Dense-8                                    (1, 120)           48120\n",
      "        Activation-9                                     (1, 84)               0\n",
      "            Dense-10                                     (1, 84)           10164\n",
      "            Dense-11                                     (1, 10)             850\n",
      "            LeNet-12                                     (1, 10)               0\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 60074\n",
      "   Trainable params: 60074\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 60074\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lenet.summary(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                                    (1, 521)               0\n",
      "        Activation-1                                    (1, 256)               0\n",
      "             Dense-2                                    (1, 256)          133632\n",
      "        Activation-3                                    (1, 123)               0\n",
      "             Dense-4                                    (1, 123)           31611\n",
      "             Dense-5                                      (1, 2)             248\n",
      "        MLP_Hybrid-6                                      (1, 2)               0\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 165491\n",
      "   Trainable params: 165491\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 165491\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net_hybrid_summary=MLP_Hybrid()\n",
    "\n",
    "net_hybrid_summary.initialize()\n",
    "\n",
    "net_hybrid_summary.summary(x_bench)\n",
    "\n",
    "net_hybrid_summary.hybridize()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
