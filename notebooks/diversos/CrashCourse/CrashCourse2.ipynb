{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando [Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/2-create-nn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create neural network\n",
    "Uma camada com 3 entradas e 5 saidas, com função de ativação \"RELU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(3 -> 5, Activation(relu))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dez linhas com três parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09709179,  0.27321362, -0.8518564 ],\n",
       "       [-0.10710186,  0.8004246 ,  0.24689186],\n",
       "       [-0.69020677,  0.9856076 , -0.9356934 ],\n",
       "       [-0.14531201,  0.75238216, -0.42828953],\n",
       "       [ 0.96896505, -0.8357303 , -0.31394452],\n",
       "       [-0.00288934, -0.00425076, -0.7892191 ],\n",
       "       [-0.45202208, -0.33587497, -0.6148413 ],\n",
       "       [ 0.7164177 , -0.08857018, -0.73732615],\n",
       "       [-0.5796278 ,  0.61682177, -0.12559462],\n",
       "       [-0.229886  , -0.88089114, -0.61813056]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.random.uniform(-1,1,(10,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04491673, 0.00914199, 0.        , 0.02022739, 0.        ],\n",
       "       [0.        , 0.02195932, 0.02917553, 0.03675443, 0.        ],\n",
       "       [0.03693289, 0.04353196, 0.        , 0.01007843, 0.        ],\n",
       "       [0.00141912, 0.02450657, 0.        , 0.03139923, 0.        ],\n",
       "       [0.0364917 , 0.        , 0.        , 0.01445661, 0.04297189],\n",
       "       [0.05382494, 0.00352589, 0.        , 0.        , 0.        ],\n",
       "       [0.06406542, 0.00277784, 0.        , 0.        , 0.        ],\n",
       "       [0.03985525, 0.        , 0.        , 0.03896289, 0.        ],\n",
       "       [0.        , 0.02803061, 0.01426389, 0.        , 0.        ],\n",
       "       [0.08207822, 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense15_ (\n",
       "  Parameter dense15_weight (shape=(5, 3), dtype=float32)\n",
       "  Parameter dense15_bias (shape=(5,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pesos e bias de entrada de cada elemento da camada interna de 5 neuronios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01926848, -0.04049358, -0.0679116 ],\n",
       "       [-0.01946345,  0.02622988, -0.00453758],\n",
       "       [-0.0105041 ,  0.02191875,  0.04255389],\n",
       "       [ 0.06167717,  0.0539865 ,  0.00059964],\n",
       "       [ 0.0258387 , -0.03875457,  0.04603765]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain layers into a neural network using nn.Sequential\n",
    "\n",
    "Sequential é a ligação de camadas onde a saída de uma camada é a entrada de outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(3 -> 5, Activation(relu))\n",
       "  (1): Dense(-1 -> 25, Activation(relu))\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "\n",
    "net.add(nn.Dense(5,in_units=3,activation='relu'),nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(-1 -> 25, Activation(relu))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom neural network architecture flexibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(5,activation='relu')\n",
    "        self.dense2=nn.Dense(25,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (dense1): Dense(-1 -> 5, Activation(relu))\n",
       "  (dense2): Dense(-1 -> 25, Activation(relu))\n",
       "  (dense3): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=MLP()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense19_ (\n",
       "  Parameter dense19_weight (shape=(5, -1), dtype=float32)\n",
       "  Parameter dense19_bias (shape=(5,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dense1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating custom layers using Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter custom_parameter_weight (shape=(5, -1), dtype=<class 'numpy.float32'>),\n",
       " Parameter custom_parameter_bias (shape=(5, -1), dtype=<class 'numpy.float32'>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon import Parameter\n",
    "\n",
    "weight=Parameter(\"custom_parameter_weight\",shape=(5,-1))\n",
    "bias=Parameter(\"custom_parameter_bias\",shape=(5,-1))\n",
    "\n",
    "weight,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layer com função linear sem função de ativação. \n",
    "\n",
    "w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_layer(nn.Block):\n",
    "    def __init__(self,out_units, in_units=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # mxnet 2.0\n",
    "        # self.weight=Parameter(\"weight\",shape=(in_units,out_units),allow_deferred_init=True)\n",
    "        # self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "        # mxnet 1.8.0\n",
    "        self.weight = self.params.get('weight', shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        self.bias = self.params.get('bias', shape=(out_units,),allow_deferred_init=True)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parameter 'weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c42e946aac6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/software/python/anaconda3/envs/d2l/lib/python3.8/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-897fcf1cd916>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/software/python/anaconda3/envs/d2l/lib/python3.8/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                \u001b[0;34m\"because its storage type is %s. Please use row_sparse_data() \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                \"instead.\" % (self.name, str(ctx), self._stype))\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_and_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/software/python/anaconda3/envs/d2l/lib/python3.8/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_check_and_get\u001b[0;34m(self, arr_list, ctx)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;34m\"You can also avoid deferred initialization by specifying in_units, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \"num_features, etc., for network layers.\"%(self.name))\n\u001b[0;32m--> 236\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0;34m\"Parameter '%s' has not been initialized. Note that \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;34m\"you should initialize parameters and create Trainer \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parameter 'weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
     ]
    }
   ],
   "source": [
    "dense=custom_layer(3,in_units=5)\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LeNet](http://yann.lecun.com/exdb/lenet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=nn.Dense(10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet=LeNet()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_custom(nn.Block):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2D(channels=6,kernel_size=3,activation='relu')\n",
    "        self.pool1=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.conv2=nn.Conv2D(channels=16,kernel_size=3,activation='relu')\n",
    "        self.pool2=nn.MaxPool2D(pool_size=2,strides=2)\n",
    "        self.dense1=nn.Dense(120,activation='relu')\n",
    "        self.dense2=nn.Dense(84,activation='relu')\n",
    "        self.dense3=custom_layer(10,84)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.pool2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        x=self.dense3(x)\n",
    "        return x\n",
    "\n",
    "lenet_custom=LeNet_custom()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data=np.random.uniform(-1,1,(1,1,28,28))\n",
    "\n",
    "lenet.initialize()\n",
    "lenet_custom.initialize()\n",
    "\n",
    "print(\"LeNet:\")\n",
    "print(lenet(image_data))\n",
    "\n",
    "print(\"Custom LeNet:\")\n",
    "print(lenet_custom(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.conv1.weight.data().shape, lenet.dense1.bias.data().shape,lenet_custom.conv1.weight.data().shape, lenet_custom.dense1.bias.data().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using predefined (pretrained) architectures\n",
    "\n",
    "[Gluon CV model zoo](https://cv.gluon.ai/model_zoo/index.html)\n",
    "\n",
    "[Gluon NLP model zoo](https://nlp.gluon.ai/model_zoo/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import model_zoo\n",
    "\n",
    "net=model_zoo.vision.resnet50_v2(pretrained=True)\n",
    "net.hybridize()\n",
    "\n",
    "dummy_input=np.ones(shape=(1,3,224,224))\n",
    "output=net(dummy_input)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding the paradigm for your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add(nn.Dense(5,in_units=3,activation='relu'),\n",
    "    nn.Dense(25,activation='relu'),nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid_seq.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom layers using Parameters(HbridBlocks API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.HybridBlock):\n",
    "    def __init__(self,out_units, in_units=-1):\n",
    "        super().__init__()\n",
    "        self.weight=Parameter(\"weight\",shape=(in_units, out_units),allow_deferred_init=True)\n",
    "        self.bias=Parameter(\"bias\",shape=(out_units,),allow_deferred_init=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(self.weight.shape,self.bias.shape)\n",
    "        return np.dot(x,self.weight.data())+self.bias.data()\n",
    "\n",
    "    def infer_shape(self,x):\n",
    "        print(self.weight.shape,x.shape)\n",
    "        self.weight.shape=(x. shape[-1],self.weight.shape[1])\n",
    "\n",
    "\n",
    "dense=CustomLayer(3)\n",
    "\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(4,5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def benchmark(net,x):\n",
    "    y=net(x)\n",
    "    start=time()\n",
    "    for i in range(1,1000):\n",
    "        y=net(x)\n",
    "    return time()-start\n",
    "\n",
    "\n",
    "x_bench=np.random.normal(size=(1,521))\n",
    "\n",
    "net_hybrid_seq=nn.HybridSequential()\n",
    "\n",
    "net_hybrid_seq.add (nn.Dense(256,activation='relu'),\n",
    "                nn.Dense(128,activation='relu'),\n",
    "                nn.Dense(2))\n",
    "\n",
    "net_hybrid_seq.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid_seq, x_bench)))\n",
    "net_hybrid_seq.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid_seq, x_bench)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import HybridBlock\n",
    "\n",
    "class MLP_Hybrid(HybridBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1=nn.Dense(256,activation='relu')\n",
    "        self.dense2=nn.Dense(123,activation='relu')\n",
    "        self.dense3=nn.Dense(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        layer1=self.dense1(x)\n",
    "        layer2=self.dense2(layer1)\n",
    "        layer3=self.dense3(layer2)\n",
    "        return layer3\n",
    "\n",
    "net_hybrid=MLP_Hybrid()\n",
    "net_hybrid.initialize()\n",
    "\n",
    "print('Before hybridizing: %.4f sec'%(benchmark(net_hybrid, x_bench)))\n",
    "net_hybrid.hybridize()\n",
    "print('After hybridizing: %.4f'%(benchmark(net_hybrid, x_bench)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Loading your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='../../../data/crashCourse/models/layer.params'\n",
    "layer.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layer=nn.Dense(5,in_units=3,activation='relu')\n",
    "    return layer\n",
    "\n",
    "layer_new=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_new.load_parameters(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/load the model weights/parameters and the architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid.export('../../../data/crashCourse/models/MLP_hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    net_loaded=nn.SymbolBlock.imports('../../../data/crashCourse/models/MLP_hybrid-symbol.json',['data'], '../../../data/crashCourse/models/MLP_hybrid-0000.params',device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loaded(x_bench)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.summary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.summary(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hybrid_summary=MLP_Hybrid()\n",
    "\n",
    "net_hybrid_summary.initialize()\n",
    "\n",
    "net_hybrid_summary.summary(x_bench)\n",
    "\n",
    "net_hybrid_summary.hybridize()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
